{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aee751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List, Any\n",
    "import datetime as dt\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "from category_encoders import CountEncoder, WOEEncoder\n",
    "from kedro.framework.session import KedroSession\n",
    "from kedro.framework.startup import bootstrap_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010b9176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:16,356 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n"
     ]
    }
   ],
   "source": [
    "# use config with base\n",
    "metadata = bootstrap_project(Path.cwd().parent.parent)\n",
    "with KedroSession.create(metadata.package_name,\n",
    "        project_path=metadata.project_path,\n",
    "        # save_on_close=True,\n",
    "        env=None,\n",
    "        # extra_params=extra_params\n",
    "    ) as session: \n",
    "    context = session.load_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f6634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_size': 0.2,\n",
       " 'random_state': 3,\n",
       " 'features': ['engines',\n",
       "  'passenger_capacity',\n",
       "  'crew',\n",
       "  'company_rating',\n",
       "  'review_scores_rating',\n",
       "  'd_check_complete',\n",
       "  'moon_clearance_complete',\n",
       "  'iata_approved'],\n",
       " 'categorical_features': ['d_check_complete',\n",
       "  'moon_clearance_complete',\n",
       "  'iata_approved'],\n",
       " 'model_params': {'hyper_parameters': {'max_depth': 7,\n",
       "   'n_estimators': 30,\n",
       "   'random_state': 555}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da946bc1",
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# regressor = xgb.sklearn.XGBRegressor(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "regressor = xgb.sklearn.XGBClassifier(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"ce\", WOEEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"float_input\", \"passthrough\", [context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]),\n",
    "        (\"categorical_input\", categorical_transformer, [context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]),\n",
    "    ],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    # Bad!\n",
    "    # (\"selector\", ColumnTransformer(\n",
    "    #     [(\"id\", \n",
    "    #       FunctionTransformer(validate=False),\n",
    "    #       list(range(len(context.params[\"features\"]))))\n",
    "    #     ])\n",
    "    # ),\n",
    "    # (\"selector\", CoulmnTransformer(FunctionTransformer(lambda X: X[:, list(range(len(context.params[\"features\"])))], validate=False))),\n",
    "    (\"precprocessor\", preprocessor),\n",
    "    (\"regressor\", regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4541b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113238f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d0eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/kedro/framework/context/context.py:488: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/kedro-sample/own_examples/conf/base', '/kedro-sample/own_examples/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:17,325 - kedro.io.data_catalog - INFO - Loading data from `X_train` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "tmp = context.catalog.load(\"X_train\")\n",
    "tmp[context.params[\"categorical_features\"]] = tmp[context.params[\"categorical_features\"]].astype(str)\n",
    "tmp[\"aaaaa\"] = tmp.engines.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46392b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:18,090 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:18,122 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25cde79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:18,464 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:18,486 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:08:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    # tmp[context.params[\"features\"]].values\n",
    "    tmp[context.params[\"features\"]+[\"aaaaa\"]].values\n",
    "    # ,context.catalog.load(\"y_train\")\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e382d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7748882 , 0.22511178],\n",
       "       [0.00519294, 0.99480706],\n",
       "       [0.9798459 , 0.0201541 ],\n",
       "       ...,\n",
       "       [0.9973383 , 0.00266168],\n",
       "       [0.9860327 , 0.01396728],\n",
       "       [0.80912876, 0.19087121]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict_proba(tmp[context.params[\"features\"]+[\"aaaaa\"]].values)\n",
    "# ppl.predict(tmp[context.params[\"features\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48448c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:23,125 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:23,146 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "[03:08:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    tmp[context.params[\"features\"]].values\n",
    "    # ,context.catalog.load(\"y_train\")\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98597110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict(tmp[context.params[\"features\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb123c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engines</th>\n",
       "      <th>passenger_capacity</th>\n",
       "      <th>crew</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>d_check_complete</th>\n",
       "      <th>moon_clearance_complete</th>\n",
       "      <th>iata_approved</th>\n",
       "      <th>aaaaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115794</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238624</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389153</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628283</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452204</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        engines  passenger_capacity  crew  company_rating  \\\n",
       "115794      2.0                   4   3.0             1.0   \n",
       "238624      4.0                   8   5.0             1.0   \n",
       "389153      1.0                   2   1.0             1.0   \n",
       "628283      2.0                   6   2.0             1.0   \n",
       "452204      1.0                   2   1.0             1.0   \n",
       "\n",
       "        review_scores_rating d_check_complete moon_clearance_complete  \\\n",
       "115794                  96.0            False                   False   \n",
       "238624                 100.0             True                   False   \n",
       "389153                  65.0             True                   False   \n",
       "628283                 100.0             True                   False   \n",
       "452204                  60.0             True                   False   \n",
       "\n",
       "       iata_approved  aaaaa  \n",
       "115794          True    2.0  \n",
       "238624         False    4.0  \n",
       "389153         False    1.0  \n",
       "628283         False    2.0  \n",
       "452204         False    1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[context.params[\"features\"]+[\"aaaaa\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf24b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607687, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f670921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  int(TensorProto.STRING): np.dtype(np.object)\n"
     ]
    },
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'category_encoders.woe.WOEEncoder'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18372/565559214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])+1])),\n\u001b[1;32m      5\u001b[0m                 (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_onnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m     onnx_model = convert_topology(\n\u001b[1;32m    185\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         remove_identity=not intermediate, verbose=verbose)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1226\u001b[0m                         \u001b[0m_check_variable_out_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Shape2] call infer_types for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_graph_status_for_traversing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36minfer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m             raise MissingShapeCalculator(\n\u001b[1;32m    572\u001b[0m                 \"Unable to find a shape calculator for type '{}'.\".format(\n\u001b[0;32m--> 573\u001b[0;31m                     type(self.raw_operator)))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mshape_calc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'category_encoders.woe.WOEEncoder'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])+1])),\n",
    "                (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36739b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:40,922 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/kedro/framework/context/context.py:488: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/kedro-sample/own_examples/conf/base', '/kedro-sample/own_examples/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151922, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.catalog.load(\"X_test\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ccf5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:41,689 - kedro.io.data_catalog - INFO - Loading data from `regressor` (PickleDataSet)...\n",
      "2021-12-27 03:08:41,711 - kedro.io.data_catalog - INFO - Saving data to `onx` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "initial_type = [('float_input', FloatTensorType([None, 8]))]\n",
    "onx = convert_sklearn(context.catalog.load(\"regressor\"), initial_types=initial_type)\n",
    "context.catalog.save(\"onx\", onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0474a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/06_models/shuttles.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a07d6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:43,055 - kedro.io.data_catalog - INFO - Loading data from `onx` (PickleDataSet)...\n",
      "2021-12-27 03:08:43,090 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy\n",
    "sess = rt.InferenceSession(context.catalog.load(\"onx\"))\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: context.catalog.load(\"X_test\").astype(numpy.float32).values})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e5df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5788.9775],\n",
       "       [3973.5654],\n",
       "       [3594.4954],\n",
       "       ...,\n",
       "       [3748.6594],\n",
       "       [5454.851 ],\n",
       "       [4444.2515]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6a0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf2c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder as SklOrdinalEncoder\n",
    "from category_encoders import WOEEncoder, OrdinalEncoder\n",
    "from skl2onnx import update_registered_converter, get_model_alias\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.utils import check_input_and_output_numbers\n",
    "from skl2onnx.algebra.onnx_ops import OnnxCast\n",
    "from skl2onnx.algebra.onnx_operator import OnnxSubEstimator\n",
    "from skl2onnx.sklapi import WOETransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6966aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordenc_to_sklearn(op_mapping):\n",
    "    \"Converts OrdinalEncoder mapping to scikit-learn OrdinalEncoder.\"\n",
    "    cats = []\n",
    "    for column_map in op_mapping:\n",
    "        col = column_map['col']\n",
    "        while len(cats) <= col:\n",
    "            cats.append(None)\n",
    "        mapping = column_map['mapping']\n",
    "        res = []\n",
    "        for i in range(mapping.shape[0]):\n",
    "            if mapping.index[i]!=mapping.index[i]:\n",
    "                continue\n",
    "            ind = mapping.iloc[i]\n",
    "            while len(res) <= ind:\n",
    "                res.append(0)\n",
    "            res[ind] = mapping.index[i]\n",
    "        cats[col] = np.array(res, dtype=\"O\")\n",
    "\n",
    "    skl_ord = SklOrdinalEncoder(categories=cats, dtype=np.int64)\n",
    "    skl_ord.categories_ = cats\n",
    "    return skl_ord\n",
    "\n",
    "\n",
    "def ordinal_encoder_shape_calculator(operator):\n",
    "    check_input_and_output_numbers(\n",
    "        operator, input_count_range=1, output_count_range=1)\n",
    "    input_type = operator.inputs[0].type.__class__\n",
    "    input_dim = operator.inputs[0].get_first_dimension()\n",
    "    shape = operator.inputs[0].type.shape\n",
    "    second_dim = None if len(shape) != 2 else shape[1]\n",
    "    output_type = input_type([input_dim, second_dim])\n",
    "    operator.outputs[0].type = output_type\n",
    "\n",
    "\n",
    "def ordinal_encoder_converter(scope, operator, container):\n",
    "    op = operator.raw_operator\n",
    "    opv = container.target_opset\n",
    "    X = operator.inputs[0]\n",
    "\n",
    "    skl_ord = ordenc_to_sklearn(op.mapping)\n",
    "    cat = OnnxSubEstimator(skl_ord, X, op_version=opv,\n",
    "                           output_names=operator.outputs[:1])\n",
    "    cat.add_to(scope, container)\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    OrdinalEncoder, \"CategoricalEncoderOrdinalEncoder\",\n",
    "    ordinal_encoder_shape_calculator,\n",
    "    ordinal_encoder_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96df57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def woeenc_to_sklearn(op_mapping):\n",
    "    \"Converts WOEEncoder mapping to scikit-learn OrdinalEncoder.\"\n",
    "    cats = []\n",
    "    ws = []\n",
    "    for column_map in op_mapping.items():\n",
    "        col = column_map[0]\n",
    "        while len(cats) <= col:\n",
    "            cats.append('passthrough')\n",
    "            ws.append(None)\n",
    "        mapping = column_map[1]\n",
    "        intervals = []\n",
    "        weights = []\n",
    "        for i in range(mapping.shape[0]):\n",
    "            ind = mapping.index[i]\n",
    "            if ind < 0:\n",
    "                continue\n",
    "            intervals.append((float(ind - 1), float(ind), False, True))\n",
    "            weights.append(mapping.iloc[i])\n",
    "        cats[col] = intervals\n",
    "        ws[col] = weights\n",
    "\n",
    "    skl = WOETransformer(intervals=cats, weights=ws, onehot=False)\n",
    "    skl.fit(None)\n",
    "    return skl\n",
    "\n",
    "\n",
    "def woe_encoder_parser(\n",
    "        scope, model, inputs, custom_parsers=None):\n",
    "    if len(inputs) != 1:\n",
    "        raise RuntimeError(\n",
    "            \"Unexpected number of inputs: %d != 1.\" % len(inputs))\n",
    "    if inputs[0].type is None:\n",
    "        raise RuntimeError(\n",
    "            \"Unexpected type: %r.\" % (inputs[0], ))\n",
    "    alias = get_model_alias(type(model))\n",
    "    this_operator = scope.declare_local_operator(alias, model)\n",
    "    this_operator.inputs.append(inputs[0])\n",
    "    this_operator.outputs.append(\n",
    "        scope.declare_local_variable('catwoe', FloatTensorType()))\n",
    "    return this_operator.outputs\n",
    "\n",
    "\n",
    "def woe_encoder_shape_calculator(operator):\n",
    "    check_input_and_output_numbers(\n",
    "        operator, input_count_range=1, output_count_range=1)\n",
    "    input_dim = operator.inputs[0].get_first_dimension()\n",
    "    shape = operator.inputs[0].type.shape\n",
    "    second_dim = None if len(shape) != 2 else shape[1]\n",
    "    output_type = FloatTensorType([input_dim, second_dim])\n",
    "    operator.outputs[0].type = output_type\n",
    "\n",
    "\n",
    "def woe_encoder_converter(scope, operator, container):\n",
    "    op = operator.raw_operator\n",
    "    opv = container.target_opset\n",
    "    X = operator.inputs[0]\n",
    "\n",
    "    sub = OnnxSubEstimator(op.ordinal_encoder, X,\n",
    "                           op_version=opv)\n",
    "    cast = OnnxCast(sub, op_version=opv, to=np.float32)\n",
    "    skl_ord = woeenc_to_sklearn(op.mapping)\n",
    "    cat = OnnxSubEstimator(skl_ord, cast, op_version=opv,\n",
    "                           output_names=operator.outputs[:1],\n",
    "                           input_types=[FloatTensorType()])\n",
    "    cat.add_to(scope, container)\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    WOEEncoder, \"CategoricalEncoderWOEEncoder\",\n",
    "    woe_encoder_shape_calculator,\n",
    "    woe_encoder_converter,\n",
    "    parser=woe_encoder_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0085adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "\n",
    "update_registered_converter(\n",
    "    XGBClassifier, 'XGBoostXGBClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df426802",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"we\", WOEEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", \"passthrough\", [context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]),\n",
    "        (\"categorical\", categorical_transformer, [context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]),\n",
    "    ],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"precprocessor\", preprocessor),\n",
    "    (\"regressor\", classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "007ec169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:36:51,795 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:36:51,819 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "[03:36:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    tmp[context.params[\"features\"]].values\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "00b5d831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "085ed52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])])),\n",
    "                (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type, target_opset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4037d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/06_models/pipeline.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6aad0bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 04:12:08,194 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n",
      "2021-12-27 04:12:08,226 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(model_onnx.SerializeToString())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[1].name\n",
    "inpt = {\n",
    "    sess.get_inputs()[0].name: context.catalog.load(\"X_test\")[context.params[\"float_features\"]].astype(numpy.float32).values,\n",
    "    sess.get_inputs()[1].name: context.catalog.load(\"X_test\")[context.params[\"categorical_features\"]].astype(str).values\n",
    "}\n",
    "pred_onx = sess.run([label_name], inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f21bd330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.0077075958251953125, 1: 0.9922924041748047},\n",
       " {0: 0.9024969339370728, 1: 0.09750306606292725},\n",
       " {0: 0.39169496297836304, 1: 0.608305037021637},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.98746258020401, 1: 0.01253741979598999},\n",
       " {0: 0.8565497398376465, 1: 0.14345026016235352},\n",
       " {0: 0.9207722544670105, 1: 0.0792277455329895},\n",
       " {0: 0.9770506620407104, 1: 0.02294933795928955},\n",
       " {0: 0.1711115837097168, 1: 0.8288884162902832},\n",
       " {0: 0.9536086320877075, 1: 0.04639136791229248},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.7143669128417969, 1: 0.2856330871582031},\n",
       " {0: 0.8365088701248169, 1: 0.1634911298751831},\n",
       " {0: 0.0036037564277648926, 1: 0.9963962435722351},\n",
       " {0: 0.15721732378005981, 1: 0.8427826762199402},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.936125636100769, 1: 0.06387436389923096},\n",
       " {0: 0.027588844299316406, 1: 0.9724111557006836},\n",
       " {0: 0.7959222197532654, 1: 0.20407778024673462},\n",
       " {0: 0.17331993579864502, 1: 0.826680064201355},\n",
       " {0: 0.7163070440292358, 1: 0.28369295597076416},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.04639798402786255, 1: 0.9536020159721375},\n",
       " {0: 0.9788869619369507, 1: 0.021113038063049316},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.005336403846740723, 1: 0.9946635961532593},\n",
       " {0: 0.0030831098556518555, 1: 0.9969168901443481},\n",
       " {0: 0.10513937473297119, 1: 0.8948606252670288},\n",
       " {0: 0.9275724291801453, 1: 0.07242757081985474},\n",
       " {0: 0.06798475980758667, 1: 0.9320152401924133},\n",
       " {0: 0.3364686965942383, 1: 0.6635313034057617},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.10513937473297119, 1: 0.8948606252670288},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.9857726693153381, 1: 0.014227330684661865},\n",
       " {0: 0.8445323705673218, 1: 0.15546762943267822},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.7001997828483582, 1: 0.29980021715164185},\n",
       " {0: 0.7344350218772888, 1: 0.2655649781227112},\n",
       " {0: 0.9967982172966003, 1: 0.003201782703399658},\n",
       " {0: 0.9958264231681824, 1: 0.004173576831817627},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9972580671310425, 1: 0.0027419328689575195},\n",
       " {0: 0.5436421632766724, 1: 0.45635783672332764},\n",
       " {0: 0.9612671136856079, 1: 0.03873288631439209},\n",
       " {0: 0.814443826675415, 1: 0.18555617332458496},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.09485012292861938, 1: 0.9051498770713806},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.005044877529144287, 1: 0.9949551224708557},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.9599877595901489, 1: 0.040012240409851074},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.9893043041229248, 1: 0.010695695877075195},\n",
       " {0: 0.9104859232902527, 1: 0.08951407670974731},\n",
       " {0: 0.9530636668205261, 1: 0.04693633317947388},\n",
       " {0: 0.9948719143867493, 1: 0.005128085613250732},\n",
       " {0: 0.6905384063720703, 1: 0.3094615936279297},\n",
       " {0: 0.004022002220153809, 1: 0.9959779977798462},\n",
       " {0: 0.9897312521934509, 1: 0.010268747806549072},\n",
       " {0: 0.012301087379455566, 1: 0.9876989126205444},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.9522015452384949, 1: 0.04779845476150513},\n",
       " {0: 0.9104859232902527, 1: 0.08951407670974731},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.9544971585273743, 1: 0.04550284147262573},\n",
       " {0: 0.1711115837097168, 1: 0.8288884162902832},\n",
       " {0: 0.9102042317390442, 1: 0.08979576826095581},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.9967982172966003, 1: 0.003201782703399658},\n",
       " {0: 0.637686550617218, 1: 0.362313449382782},\n",
       " {0: 0.49012261629104614, 1: 0.5098773837089539},\n",
       " {0: 0.008660495281219482, 1: 0.9913395047187805},\n",
       " {0: 0.9918708801269531, 1: 0.008129119873046875},\n",
       " {0: 0.5436421632766724, 1: 0.45635783672332764},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.9483095407485962, 1: 0.05169045925140381},\n",
       " {0: 0.9939688444137573, 1: 0.006031155586242676},\n",
       " {0: 0.9984304308891296, 1: 0.0015695691108703613},\n",
       " {0: 0.5436421632766724, 1: 0.45635783672332764},\n",
       " {0: 0.9969791173934937, 1: 0.0030208826065063477},\n",
       " {0: 0.9983508586883545, 1: 0.0016491413116455078},\n",
       " {0: 0.9822739958763123, 1: 0.017726004123687744},\n",
       " {0: 0.7344350218772888, 1: 0.2655649781227112},\n",
       " {0: 0.03459572792053223, 1: 0.9654042720794678},\n",
       " {0: 0.004362046718597412, 1: 0.9956379532814026},\n",
       " {0: 0.47264158725738525, 1: 0.5273584127426147},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9940288066864014, 1: 0.005971193313598633},\n",
       " {0: 0.9737086296081543, 1: 0.026291370391845703},\n",
       " {0: 0.010437190532684326, 1: 0.9895628094673157},\n",
       " {0: 0.3834582567214966, 1: 0.6165417432785034},\n",
       " {0: 0.9695264101028442, 1: 0.03047358989715576},\n",
       " {0: 0.012301087379455566, 1: 0.9876989126205444},\n",
       " {0: 0.9931613206863403, 1: 0.006838679313659668},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.28582215309143066, 1: 0.7141778469085693},\n",
       " {0: 0.9984637498855591, 1: 0.001536250114440918},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.9883648157119751, 1: 0.011635184288024902},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.7056172490119934, 1: 0.2943827509880066},\n",
       " {0: 0.620324432849884, 1: 0.37967556715011597},\n",
       " {0: 0.18410736322402954, 1: 0.8158926367759705},\n",
       " {0: 0.9929404258728027, 1: 0.007059574127197266},\n",
       " {0: 0.9728020429611206, 1: 0.027197957038879395},\n",
       " {0: 0.375521183013916, 1: 0.624478816986084},\n",
       " {0: 0.006645321846008301, 1: 0.9933546781539917},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9908865690231323, 1: 0.009113430976867676},\n",
       " {0: 0.9463711977005005, 1: 0.05362880229949951},\n",
       " {0: 0.34673523902893066, 1: 0.6532647609710693},\n",
       " {0: 0.8961594700813293, 1: 0.10384052991867065},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9686698317527771, 1: 0.0313301682472229},\n",
       " {0: 0.9953981041908264, 1: 0.004601895809173584},\n",
       " {0: 0.9950169920921326, 1: 0.004983007907867432},\n",
       " {0: 0.9990690350532532, 1: 0.0009309649467468262},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9908865690231323, 1: 0.009113430976867676},\n",
       " {0: 0.0030831098556518555, 1: 0.9969168901443481},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.9603449106216431, 1: 0.039655089378356934},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.5365029573440552, 1: 0.4634970426559448},\n",
       " {0: 0.9993358254432678, 1: 0.0006641745567321777},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.014215528964996338, 1: 0.9857844710350037},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.9585064649581909, 1: 0.04149353504180908},\n",
       " {0: 0.0036037564277648926, 1: 0.9963962435722351},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9864994287490845, 1: 0.013500571250915527},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9278921484947205, 1: 0.07210785150527954},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.00927501916885376, 1: 0.9907249808311462},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.9876294136047363, 1: 0.012370586395263672},\n",
       " {0: 0.08216279745101929, 1: 0.9178372025489807},\n",
       " {0: 0.9929094314575195, 1: 0.007090568542480469},\n",
       " {0: 0.06798475980758667, 1: 0.9320152401924133},\n",
       " {0: 0.7344350218772888, 1: 0.2655649781227112},\n",
       " {0: 0.9974364638328552, 1: 0.0025635361671447754},\n",
       " {0: 0.9966841340065002, 1: 0.003315865993499756},\n",
       " {0: 0.9981508851051331, 1: 0.0018491148948669434},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.12184816598892212, 1: 0.8781518340110779},\n",
       " {0: 0.8233298063278198, 1: 0.17667019367218018},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.9522015452384949, 1: 0.04779845476150513},\n",
       " {0: 0.9629926681518555, 1: 0.03700733184814453},\n",
       " {0: 0.9929231405258179, 1: 0.007076859474182129},\n",
       " {0: 0.7657669186592102, 1: 0.2342330813407898},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.5892137289047241, 1: 0.4107862710952759},\n",
       " {0: 0.9984251260757446, 1: 0.001574873924255371},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.7630290389060974, 1: 0.2369709610939026},\n",
       " {0: 0.9614136219024658, 1: 0.03858637809753418},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.7659306526184082, 1: 0.2340693473815918},\n",
       " {0: 0.9978261590003967, 1: 0.0021738409996032715},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9505792260169983, 1: 0.04942077398300171},\n",
       " {0: 0.003150761127471924, 1: 0.9968492388725281},\n",
       " {0: 0.9807323813438416, 1: 0.019267618656158447},\n",
       " {0: 0.9911276698112488, 1: 0.00887233018875122},\n",
       " {0: 0.020225048065185547, 1: 0.9797749519348145},\n",
       " {0: 0.9863713383674622, 1: 0.013628661632537842},\n",
       " {0: 0.9472690224647522, 1: 0.0527309775352478},\n",
       " {0: 0.8766632080078125, 1: 0.1233367919921875},\n",
       " {0: 0.013687670230865479, 1: 0.9863123297691345},\n",
       " {0: 0.8791912198066711, 1: 0.12080878019332886},\n",
       " {0: 0.8769826889038086, 1: 0.1230173110961914},\n",
       " {0: 0.004362046718597412, 1: 0.9956379532814026},\n",
       " {0: 0.999042809009552, 1: 0.000957190990447998},\n",
       " {0: 0.021852314472198486, 1: 0.9781476855278015},\n",
       " {0: 0.008217334747314453, 1: 0.9917826652526855},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.9984562397003174, 1: 0.0015437602996826172},\n",
       " {0: 0.9473990201950073, 1: 0.052600979804992676},\n",
       " {0: 0.04639798402786255, 1: 0.9536020159721375},\n",
       " {0: 0.05010020732879639, 1: 0.9498997926712036},\n",
       " {0: 0.006260871887207031, 1: 0.993739128112793},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.9861887097358704, 1: 0.013811290264129639},\n",
       " {0: 0.9608273506164551, 1: 0.03917264938354492},\n",
       " {0: 0.008660495281219482, 1: 0.9913395047187805},\n",
       " {0: 0.8784707188606262, 1: 0.12152928113937378},\n",
       " {0: 0.7612386345863342, 1: 0.23876136541366577},\n",
       " {0: 0.00546574592590332, 1: 0.9945342540740967},\n",
       " {0: 0.9957177042961121, 1: 0.0042822957038879395},\n",
       " {0: 0.968665361404419, 1: 0.031334638595581055},\n",
       " {0: 0.5206026434898376, 1: 0.47939735651016235},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.5722172260284424, 1: 0.4277827739715576},\n",
       " {0: 0.9994550347328186, 1: 0.0005449652671813965},\n",
       " {0: 0.9939841628074646, 1: 0.0060158371925354},\n",
       " {0: 0.9947108030319214, 1: 0.005289196968078613},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.8442471027374268, 1: 0.15575289726257324},\n",
       " {0: 0.8970522284507751, 1: 0.10294777154922485},\n",
       " {0: 0.6630282998085022, 1: 0.3369717001914978},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9906576871871948, 1: 0.009342312812805176},\n",
       " {0: 0.02482980489730835, 1: 0.9751701951026917},\n",
       " {0: 0.057643353939056396, 1: 0.9423566460609436},\n",
       " {0: 0.03756958246231079, 1: 0.9624304175376892},\n",
       " {0: 0.9638819694519043, 1: 0.0361180305480957},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.001548171043395996, 1: 0.998451828956604},\n",
       " {0: 0.7460737824440002, 1: 0.25392621755599976},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.09063959121704102, 1: 0.909360408782959},\n",
       " {0: 0.10560113191604614, 1: 0.8943988680839539},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.6974310874938965, 1: 0.3025689125061035},\n",
       " {0: 0.05667436122894287, 1: 0.9433256387710571},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9782282114028931, 1: 0.021771788597106934},\n",
       " {0: 0.9985615611076355, 1: 0.001438438892364502},\n",
       " {0: 0.7874236702919006, 1: 0.21257632970809937},\n",
       " {0: 0.010519146919250488, 1: 0.9894808530807495},\n",
       " {0: 0.9957019686698914, 1: 0.004298031330108643},\n",
       " {0: 0.9990355968475342, 1: 0.0009644031524658203},\n",
       " {0: 0.9790638089179993, 1: 0.020936191082000732},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.007599830627441406, 1: 0.9924001693725586},\n",
       " {0: 0.0037493109703063965, 1: 0.9962506890296936},\n",
       " {0: 0.8655325174331665, 1: 0.1344674825668335},\n",
       " {0: 0.9603797793388367, 1: 0.03962022066116333},\n",
       " {0: 0.9638819694519043, 1: 0.0361180305480957},\n",
       " {0: 0.9739185571670532, 1: 0.026081442832946777},\n",
       " {0: 0.36567211151123047, 1: 0.6343278884887695},\n",
       " {0: 0.7146903872489929, 1: 0.2853096127510071},\n",
       " {0: 0.9950169920921326, 1: 0.004983007907867432},\n",
       " {0: 0.783393919467926, 1: 0.21660608053207397},\n",
       " {0: 0.9910427331924438, 1: 0.008957266807556152},\n",
       " {0: 0.9207722544670105, 1: 0.0792277455329895},\n",
       " {0: 0.7888070940971375, 1: 0.21119290590286255},\n",
       " {0: 0.998916745185852, 1: 0.0010832548141479492},\n",
       " {0: 0.0071378350257873535, 1: 0.9928621649742126},\n",
       " {0: 0.49853432178497314, 1: 0.5014656782150269},\n",
       " {0: 0.41562342643737793, 1: 0.5843765735626221},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9829190969467163, 1: 0.01708090305328369},\n",
       " {0: 0.9967358708381653, 1: 0.003264129161834717},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9953006505966187, 1: 0.004699349403381348},\n",
       " {0: 0.9798459410667419, 1: 0.020154058933258057},\n",
       " {0: 0.9953006505966187, 1: 0.004699349403381348},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.6902227401733398, 1: 0.30977725982666016},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.9325396418571472, 1: 0.06746035814285278},\n",
       " {0: 0.9989902377128601, 1: 0.0010097622871398926},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.007870912551879883, 1: 0.9921290874481201},\n",
       " {0: 0.8519195318222046, 1: 0.1480804681777954},\n",
       " {0: 0.9788835048675537, 1: 0.02111649513244629},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.992379903793335, 1: 0.007620096206665039},\n",
       " {0: 0.9930315017700195, 1: 0.006968498229980469},\n",
       " {0: 0.9453303217887878, 1: 0.05466967821121216},\n",
       " {0: 0.9861887097358704, 1: 0.013811290264129639},\n",
       " {0: 0.992379903793335, 1: 0.007620096206665039},\n",
       " {0: 0.015446662902832031, 1: 0.984553337097168},\n",
       " {0: 0.9932581186294556, 1: 0.006741881370544434},\n",
       " {0: 0.17810887098312378, 1: 0.8218911290168762},\n",
       " {0: 0.9585064649581909, 1: 0.04149353504180908},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.9305076003074646, 1: 0.0694923996925354},\n",
       " {0: 0.9846866726875305, 1: 0.015313327312469482},\n",
       " {0: 0.007599830627441406, 1: 0.9924001693725586},\n",
       " {0: 0.992379903793335, 1: 0.007620096206665039},\n",
       " {0: 0.4539150595664978, 1: 0.5460849404335022},\n",
       " {0: 0.9466460347175598, 1: 0.053353965282440186},\n",
       " {0: 0.8784707188606262, 1: 0.12152928113937378},\n",
       " {0: 0.8826614618301392, 1: 0.11733853816986084},\n",
       " {0: 0.04639798402786255, 1: 0.9536020159721375},\n",
       " {0: 0.9774162769317627, 1: 0.022583723068237305},\n",
       " {0: 0.12628406286239624, 1: 0.8737159371376038},\n",
       " {0: 0.993878960609436, 1: 0.006121039390563965},\n",
       " {0: 0.7143669128417969, 1: 0.2856330871582031},\n",
       " {0: 0.1307266354560852, 1: 0.8692733645439148},\n",
       " {0: 0.23038655519485474, 1: 0.7696134448051453},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.019312143325805664, 1: 0.9806878566741943},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.9953006505966187, 1: 0.004699349403381348},\n",
       " {0: 0.9861887097358704, 1: 0.013811290264129639},\n",
       " {0: 0.8715423941612244, 1: 0.12845760583877563},\n",
       " {0: 0.903535008430481, 1: 0.09646499156951904},\n",
       " {0: 0.8769826889038086, 1: 0.1230173110961914},\n",
       " {0: 0.983157217502594, 1: 0.016842782497406006},\n",
       " {0: 0.5206026434898376, 1: 0.47939735651016235},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.9859014749526978, 1: 0.014098525047302246},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9929314851760864, 1: 0.007068514823913574},\n",
       " {0: 0.9872390627861023, 1: 0.012760937213897705},\n",
       " {0: 0.9585064649581909, 1: 0.04149353504180908},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.010600924491882324, 1: 0.9893990755081177},\n",
       " {0: 0.0037493109703063965, 1: 0.9962506890296936},\n",
       " {0: 0.9926517605781555, 1: 0.007348239421844482},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9846163988113403, 1: 0.015383601188659668},\n",
       " {0: 0.004022002220153809, 1: 0.9959779977798462},\n",
       " {0: 0.007182121276855469, 1: 0.9928178787231445},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.010437190532684326, 1: 0.9895628094673157},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.06514698266983032, 1: 0.9348530173301697},\n",
       " {0: 0.9932581186294556, 1: 0.006741881370544434},\n",
       " {0: 0.9009580016136169, 1: 0.09904199838638306},\n",
       " {0: 0.9950169920921326, 1: 0.004983007907867432},\n",
       " {0: 0.9286331534385681, 1: 0.07136684656143188},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.7209474444389343, 1: 0.2790525555610657},\n",
       " {0: 0.006714046001434326, 1: 0.9932859539985657},\n",
       " {0: 0.8445323705673218, 1: 0.15546762943267822},\n",
       " {0: 0.0042612552642822266, 1: 0.9957387447357178},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.9565633535385132, 1: 0.043436646461486816},\n",
       " {0: 0.8584163188934326, 1: 0.14158368110656738},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.9893043041229248, 1: 0.010695695877075195},\n",
       " {0: 0.9739185571670532, 1: 0.026081442832946777},\n",
       " {0: 0.9950169920921326, 1: 0.004983007907867432},\n",
       " {0: 0.18410736322402954, 1: 0.8158926367759705},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.5365029573440552, 1: 0.4634970426559448},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9953006505966187, 1: 0.004699349403381348},\n",
       " {0: 0.7959222197532654, 1: 0.20407778024673462},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9621947407722473, 1: 0.037805259227752686},\n",
       " {0: 0.7143669128417969, 1: 0.2856330871582031},\n",
       " {0: 0.9839293956756592, 1: 0.01607060432434082},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.9740625023841858, 1: 0.02593749761581421},\n",
       " {0: 0.013731956481933594, 1: 0.9862680435180664},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9798459410667419, 1: 0.020154058933258057},\n",
       " {0: 0.004362046718597412, 1: 0.9956379532814026},\n",
       " {0: 0.9064326286315918, 1: 0.0935673713684082},\n",
       " {0: 0.9477834701538086, 1: 0.052216529846191406},\n",
       " {0: 0.2788711190223694, 1: 0.7211288809776306},\n",
       " {0: 0.9797928333282471, 1: 0.02020716667175293},\n",
       " {0: 0.9694454669952393, 1: 0.030554533004760742},\n",
       " {0: 0.9649277329444885, 1: 0.035072267055511475},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.9565633535385132, 1: 0.043436646461486816},\n",
       " {0: 0.9727162718772888, 1: 0.02728372812271118},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.9207722544670105, 1: 0.0792277455329895},\n",
       " {0: 0.5206026434898376, 1: 0.47939735651016235},\n",
       " {0: 0.9913845062255859, 1: 0.008615493774414062},\n",
       " {0: 0.9872632622718811, 1: 0.012736737728118896},\n",
       " {0: 0.014215528964996338, 1: 0.9857844710350037},\n",
       " {0: 0.07381659746170044, 1: 0.9261834025382996},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.0042612552642822266, 1: 0.9957387447357178},\n",
       " {0: 0.9959403276443481, 1: 0.0040596723556518555},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.8813745975494385, 1: 0.11862540245056152},\n",
       " {0: 0.057643353939056396, 1: 0.9423566460609436},\n",
       " {0: 0.9598594307899475, 1: 0.04014056921005249},\n",
       " {0: 0.9638819694519043, 1: 0.0361180305480957},\n",
       " {0: 0.9816111326217651, 1: 0.018388867378234863},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.9706225991249084, 1: 0.029377400875091553},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.5436421632766724, 1: 0.45635783672332764},\n",
       " {0: 0.004022002220153809, 1: 0.9959779977798462},\n",
       " {0: 0.8442637324333191, 1: 0.1557362675666809},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.7550110220909119, 1: 0.24498897790908813},\n",
       " {0: 0.9463711977005005, 1: 0.05362880229949951},\n",
       " {0: 0.9388766288757324, 1: 0.06112337112426758},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.6016857028007507, 1: 0.39831429719924927},\n",
       " {0: 0.2788711190223694, 1: 0.7211288809776306},\n",
       " {0: 0.9970545768737793, 1: 0.002945423126220703},\n",
       " {0: 0.8289678692817688, 1: 0.1710321307182312},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.6171985864639282, 1: 0.3828014135360718},\n",
       " {0: 0.9782282114028931, 1: 0.021771788597106934},\n",
       " {0: 0.03282207250595093, 1: 0.9671779274940491},\n",
       " {0: 0.9649277329444885, 1: 0.035072267055511475},\n",
       " {0: 0.9715032577514648, 1: 0.028496742248535156},\n",
       " {0: 0.7146903872489929, 1: 0.2853096127510071},\n",
       " {0: 0.8524753451347351, 1: 0.1475246548652649},\n",
       " {0: 0.8961594700813293, 1: 0.10384052991867065},\n",
       " {0: 0.9888004064559937, 1: 0.011199593544006348},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9585064649581909, 1: 0.04149353504180908},\n",
       " {0: 0.018768250942230225, 1: 0.9812317490577698},\n",
       " {0: 0.8380910754203796, 1: 0.16190892457962036},\n",
       " {0: 0.4539150595664978, 1: 0.5460849404335022},\n",
       " {0: 0.9926517605781555, 1: 0.007348239421844482},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.0031633377075195312, 1: 0.9968366622924805},\n",
       " {0: 0.03756958246231079, 1: 0.9624304175376892},\n",
       " {0: 0.9915971159934998, 1: 0.008402884006500244},\n",
       " {0: 0.9471489191055298, 1: 0.052851080894470215},\n",
       " {0: 0.9812067151069641, 1: 0.01879328489303589},\n",
       " {0: 0.27593880891799927, 1: 0.7240611910820007},\n",
       " {0: 0.9864994287490845, 1: 0.013500571250915527},\n",
       " {0: 0.903535008430481, 1: 0.09646499156951904},\n",
       " {0: 0.03618049621582031, 1: 0.9638195037841797},\n",
       " {0: 0.9989615678787231, 1: 0.0010384321212768555},\n",
       " {0: 0.9996962547302246, 1: 0.0003037452697753906},\n",
       " {0: 0.8747185468673706, 1: 0.1252814531326294},\n",
       " {0: 0.993861198425293, 1: 0.006138801574707031},\n",
       " {0: 0.9974364638328552, 1: 0.0025635361671447754},\n",
       " {0: 0.07997256517410278, 1: 0.9200274348258972},\n",
       " {0: 0.8442471027374268, 1: 0.15575289726257324},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9931706190109253, 1: 0.006829380989074707},\n",
       " {0: 0.9898970127105713, 1: 0.010102987289428711},\n",
       " {0: 0.9889950156211853, 1: 0.011004984378814697},\n",
       " {0: 0.005027651786804199, 1: 0.9949723482131958},\n",
       " {0: 0.9920380115509033, 1: 0.00796198844909668},\n",
       " {0: 0.8048499226570129, 1: 0.19515007734298706},\n",
       " {0: 0.9868406057357788, 1: 0.013159394264221191},\n",
       " {0: 0.05347257852554321, 1: 0.9465274214744568},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.8233298063278198, 1: 0.17667019367218018},\n",
       " {0: 0.8034467697143555, 1: 0.19655323028564453},\n",
       " {0: 0.6244694590568542, 1: 0.37553054094314575},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.8952153921127319, 1: 0.10478460788726807},\n",
       " {0: 0.9929314851760864, 1: 0.007068514823913574},\n",
       " {0: 0.99302738904953, 1: 0.006972610950469971},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.022622883319854736, 1: 0.9773771166801453},\n",
       " {0: 0.007627606391906738, 1: 0.9923723936080933},\n",
       " {0: 0.7801820039749146, 1: 0.21981799602508545},\n",
       " {0: 0.9977355003356934, 1: 0.0022644996643066406},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9318720698356628, 1: 0.06812793016433716},\n",
       " {0: 0.04639798402786255, 1: 0.9536020159721375},\n",
       " {0: 0.9944314360618591, 1: 0.005568563938140869},\n",
       " {0: 0.10429620742797852, 1: 0.8957037925720215},\n",
       " {0: 0.9561490416526794, 1: 0.04385095834732056},\n",
       " {0: 0.3379531502723694, 1: 0.6620468497276306},\n",
       " {0: 0.9958208799362183, 1: 0.004179120063781738},\n",
       " {0: 0.009443938732147217, 1: 0.9905560612678528},\n",
       " {0: 0.7258133888244629, 1: 0.2741866111755371},\n",
       " {0: 0.010600924491882324, 1: 0.9893990755081177},\n",
       " {0: 0.9936535358428955, 1: 0.006346464157104492},\n",
       " {0: 0.08305680751800537, 1: 0.9169431924819946},\n",
       " {0: 0.0030831098556518555, 1: 0.9969168901443481},\n",
       " {0: 0.9886190891265869, 1: 0.011380910873413086},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.7325636744499207, 1: 0.26743632555007935},\n",
       " {0: 0.07997256517410278, 1: 0.9200274348258972},\n",
       " {0: 0.7959222197532654, 1: 0.20407778024673462},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.010600924491882324, 1: 0.9893990755081177},\n",
       " {0: 0.9915865659713745, 1: 0.008413434028625488},\n",
       " {0: 0.5043573379516602, 1: 0.49564266204833984},\n",
       " {0: 0.9888400435447693, 1: 0.011159956455230713},\n",
       " {0: 0.9930410385131836, 1: 0.006958961486816406},\n",
       " {0: 0.7460737824440002, 1: 0.25392621755599976},\n",
       " {0: 0.993910551071167, 1: 0.006089448928833008},\n",
       " {0: 0.9741150140762329, 1: 0.02588498592376709},\n",
       " {0: 0.9453303217887878, 1: 0.05466967821121216},\n",
       " {0: 0.9294473528862, 1: 0.07055264711380005},\n",
       " {0: 0.9962412118911743, 1: 0.0037587881088256836},\n",
       " {0: 0.4069892168045044, 1: 0.5930107831954956},\n",
       " {0: 0.978116512298584, 1: 0.021883487701416016},\n",
       " {0: 0.9743470549583435, 1: 0.025652945041656494},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9869253635406494, 1: 0.013074636459350586},\n",
       " {0: 0.09489649534225464, 1: 0.9051035046577454},\n",
       " {0: 0.0038518905639648438, 1: 0.9961481094360352},\n",
       " {0: 0.003475368022918701, 1: 0.9965246319770813},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.06764721870422363, 1: 0.9323527812957764},\n",
       " {0: 0.9978199005126953, 1: 0.0021800994873046875},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.980972409248352, 1: 0.01902759075164795},\n",
       " {0: 0.9968819618225098, 1: 0.0031180381774902344},\n",
       " {0: 0.992379903793335, 1: 0.007620096206665039},\n",
       " {0: 0.8519195318222046, 1: 0.1480804681777954},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.9950169920921326, 1: 0.004983007907867432},\n",
       " {0: 0.778067409992218, 1: 0.22193259000778198},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.010519146919250488, 1: 0.9894808530807495},\n",
       " {0: 0.6244694590568542, 1: 0.37553054094314575},\n",
       " {0: 0.9426407217979431, 1: 0.057359278202056885},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.005027651786804199, 1: 0.9949723482131958},\n",
       " {0: 0.978140115737915, 1: 0.02185988426208496},\n",
       " {0: 0.004362046718597412, 1: 0.9956379532814026},\n",
       " {0: 0.993239164352417, 1: 0.006760835647583008},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.9957177042961121, 1: 0.0042822957038879395},\n",
       " {0: 0.9608273506164551, 1: 0.03917264938354492},\n",
       " {0: 0.996161937713623, 1: 0.003838062286376953},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9207722544670105, 1: 0.0792277455329895},\n",
       " {0: 0.08216279745101929, 1: 0.9178372025489807},\n",
       " {0: 0.018768250942230225, 1: 0.9812317490577698},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.9972580671310425, 1: 0.0027419328689575195},\n",
       " {0: 0.9095134139060974, 1: 0.09048658609390259},\n",
       " {0: 0.8565497398376465, 1: 0.14345026016235352},\n",
       " {0: 0.9798459410667419, 1: 0.020154058933258057},\n",
       " {0: 0.9911401867866516, 1: 0.008859813213348389},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9933128952980042, 1: 0.00668710470199585},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.9876294136047363, 1: 0.012370586395263672},\n",
       " {0: 0.7460737824440002, 1: 0.25392621755599976},\n",
       " {0: 0.6769316792488098, 1: 0.3230683207511902},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.7397146224975586, 1: 0.2602853775024414},\n",
       " {0: 0.40927523374557495, 1: 0.590724766254425},\n",
       " {0: 0.6693087816238403, 1: 0.33069121837615967},\n",
       " {0: 0.9786055684089661, 1: 0.021394431591033936},\n",
       " {0: 0.0031633377075195312, 1: 0.9968366622924805},\n",
       " {0: 0.9816812872886658, 1: 0.01831871271133423},\n",
       " {0: 0.9996962547302246, 1: 0.0003037452697753906},\n",
       " {0: 0.990510880947113, 1: 0.009489119052886963},\n",
       " {0: 0.9216212034225464, 1: 0.07837879657745361},\n",
       " {0: 0.007627606391906738, 1: 0.9923723936080933},\n",
       " {0: 0.7629647850990295, 1: 0.23703521490097046},\n",
       " {0: 0.20657551288604736, 1: 0.7934244871139526},\n",
       " {0: 0.33538395166397095, 1: 0.664616048336029},\n",
       " {0: 0.9808474779129028, 1: 0.019152522087097168},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9947108030319214, 1: 0.005289196968078613},\n",
       " {0: 0.08216279745101929, 1: 0.9178372025489807},\n",
       " {0: 0.0142936110496521, 1: 0.9857063889503479},\n",
       " {0: 0.9565633535385132, 1: 0.043436646461486816},\n",
       " {0: 0.9608273506164551, 1: 0.03917264938354492},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.009443938732147217, 1: 0.9905560612678528},\n",
       " {0: 0.9987087249755859, 1: 0.0012912750244140625},\n",
       " {0: 0.08442950248718262, 1: 0.9155704975128174},\n",
       " {0: 0.02482980489730835, 1: 0.9751701951026917},\n",
       " {0: 0.9879232048988342, 1: 0.012076795101165771},\n",
       " {0: 0.33538395166397095, 1: 0.664616048336029},\n",
       " {0: 0.1422581672668457, 1: 0.8577418327331543},\n",
       " {0: 0.9729774594306946, 1: 0.02702254056930542},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.15575212240219116, 1: 0.8442478775978088},\n",
       " {0: 0.7801820039749146, 1: 0.21981799602508545},\n",
       " {0: 0.9649277329444885, 1: 0.035072267055511475},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9275724291801453, 1: 0.07242757081985474},\n",
       " {0: 0.6171985864639282, 1: 0.3828014135360718},\n",
       " {0: 0.9939968585968018, 1: 0.006003141403198242},\n",
       " {0: 0.9882853031158447, 1: 0.011714696884155273},\n",
       " {0: 0.2711523771286011, 1: 0.7288476228713989},\n",
       " {0: 0.17810887098312378, 1: 0.8218911290168762},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.9934136271476746, 1: 0.0065863728523254395},\n",
       " {0: 0.38783329725265503, 1: 0.612166702747345},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.6568163633346558, 1: 0.34318363666534424},\n",
       " {0: 0.9470891356468201, 1: 0.05291086435317993},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.8202434182167053, 1: 0.17975658178329468},\n",
       " {0: 0.9959926009178162, 1: 0.004007399082183838},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9876294136047363, 1: 0.012370586395263672},\n",
       " {0: 0.8895077705383301, 1: 0.11049222946166992},\n",
       " {0: 0.9877233505249023, 1: 0.012276649475097656},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9885053038597107, 1: 0.011494696140289307},\n",
       " {0: 0.2271997332572937, 1: 0.7728002667427063},\n",
       " {0: 0.021264970302581787, 1: 0.9787350296974182},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.39169496297836304, 1: 0.608305037021637},\n",
       " {0: 0.40927523374557495, 1: 0.590724766254425},\n",
       " {0: 0.9275724291801453, 1: 0.07242757081985474},\n",
       " {0: 0.8784707188606262, 1: 0.12152928113937378},\n",
       " {0: 0.020225048065185547, 1: 0.9797749519348145},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.04502546787261963, 1: 0.9549745321273804},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.7344350218772888, 1: 0.2655649781227112},\n",
       " {0: 0.993696391582489, 1: 0.006303608417510986},\n",
       " {0: 0.018442869186401367, 1: 0.9815571308135986},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.17810887098312378, 1: 0.8218911290168762},\n",
       " {0: 0.9893043041229248, 1: 0.010695695877075195},\n",
       " {0: 0.005027651786804199, 1: 0.9949723482131958},\n",
       " {0: 0.9993096590042114, 1: 0.0006903409957885742},\n",
       " {0: 0.778067409992218, 1: 0.22193259000778198},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.8813745975494385, 1: 0.11862540245056152},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9775981903076172, 1: 0.022401809692382812},\n",
       " {0: 0.01105797290802002, 1: 0.98894202709198},\n",
       " {0: 0.9959121942520142, 1: 0.00408780574798584},\n",
       " {0: 0.03980010747909546, 1: 0.9601998925209045},\n",
       " {0: 0.9963751435279846, 1: 0.003624856472015381},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.5365029573440552, 1: 0.4634970426559448},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.2788711190223694, 1: 0.7211288809776306},\n",
       " {0: 0.778067409992218, 1: 0.22193259000778198},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9538549780845642, 1: 0.04614502191543579},\n",
       " {0: 0.9879232048988342, 1: 0.012076795101165771},\n",
       " {0: 0.665655791759491, 1: 0.33434420824050903},\n",
       " {0: 0.9794051647186279, 1: 0.02059483528137207},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.8202434182167053, 1: 0.17975658178329468},\n",
       " {0: 0.6207401752471924, 1: 0.3792598247528076},\n",
       " {0: 0.9846866726875305, 1: 0.015313327312469482},\n",
       " {0: 0.9781553149223328, 1: 0.021844685077667236},\n",
       " {0: 0.010437190532684326, 1: 0.9895628094673157},\n",
       " {0: 0.006348013877868652, 1: 0.9936519861221313},\n",
       " {0: 0.9909312725067139, 1: 0.009068727493286133},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.005027651786804199, 1: 0.9949723482131958},\n",
       " {0: 0.9794615507125854, 1: 0.02053844928741455},\n",
       " {0: 0.9908174276351929, 1: 0.009182572364807129},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9995906949043274, 1: 0.0004093050956726074},\n",
       " {0: 0.993239164352417, 1: 0.006760835647583008},\n",
       " {0: 0.9784300327301025, 1: 0.02156996726989746},\n",
       " {0: 0.9638819694519043, 1: 0.0361180305480957},\n",
       " {0: 0.04639798402786255, 1: 0.9536020159721375},\n",
       " {0: 0.9275724291801453, 1: 0.07242757081985474},\n",
       " {0: 0.0221824049949646, 1: 0.9778175950050354},\n",
       " {0: 0.9984304308891296, 1: 0.0015695691108703613},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9953981041908264, 1: 0.004601895809173584},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.778067409992218, 1: 0.22193259000778198},\n",
       " {0: 0.9860469698905945, 1: 0.013953030109405518},\n",
       " {0: 0.01105797290802002, 1: 0.98894202709198},\n",
       " {0: 0.9844075441360474, 1: 0.015592455863952637},\n",
       " {0: 0.39169496297836304, 1: 0.608305037021637},\n",
       " {0: 0.9722614884376526, 1: 0.027738511562347412},\n",
       " {0: 0.5883859395980835, 1: 0.4116140604019165},\n",
       " {0: 0.013687670230865479, 1: 0.9863123297691345},\n",
       " {0: 0.9783233404159546, 1: 0.02167665958404541},\n",
       " {0: 0.01105797290802002, 1: 0.98894202709198},\n",
       " {0: 0.018768250942230225, 1: 0.9812317490577698},\n",
       " {0: 0.98746258020401, 1: 0.01253741979598999},\n",
       " {0: 0.5043573379516602, 1: 0.49564266204833984},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.993861198425293, 1: 0.006138801574707031},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.9970648884773254, 1: 0.0029351115226745605},\n",
       " {0: 0.057643353939056396, 1: 0.9423566460609436},\n",
       " {0: 0.9991496801376343, 1: 0.0008503198623657227},\n",
       " {0: 0.7873795032501221, 1: 0.21262049674987793},\n",
       " {0: 0.7297295928001404, 1: 0.2702704071998596},\n",
       " {0: 0.0030831098556518555, 1: 0.9969168901443481},\n",
       " {0: 0.5206026434898376, 1: 0.47939735651016235},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.00960630178451538, 1: 0.9903936982154846},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.9024969339370728, 1: 0.09750306606292725},\n",
       " {0: 0.7143669128417969, 1: 0.2856330871582031},\n",
       " {0: 0.9940557479858398, 1: 0.005944252014160156},\n",
       " {0: 0.9426407217979431, 1: 0.057359278202056885},\n",
       " {0: 0.010519146919250488, 1: 0.9894808530807495},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.008217334747314453, 1: 0.9917826652526855},\n",
       " {0: 0.00926661491394043, 1: 0.9907333850860596},\n",
       " {0: 0.9483095407485962, 1: 0.05169045925140381},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.8673341870307922, 1: 0.13266581296920776},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.8740686178207397, 1: 0.12593138217926025},\n",
       " {0: 0.010594666004180908, 1: 0.9894053339958191},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.9827520251274109, 1: 0.01724797487258911},\n",
       " {0: 0.5892311334609985, 1: 0.41076886653900146},\n",
       " {0: 0.009959161281585693, 1: 0.9900408387184143},\n",
       " {0: 0.9878343343734741, 1: 0.012165665626525879},\n",
       " {0: 0.08216279745101929, 1: 0.9178372025489807},\n",
       " {0: 0.9916081428527832, 1: 0.008391857147216797},\n",
       " {0: 0.7146903872489929, 1: 0.2853096127510071},\n",
       " {0: 0.9879232048988342, 1: 0.012076795101165771},\n",
       " {0: 0.06537747383117676, 1: 0.9346225261688232},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.9854373931884766, 1: 0.014562606811523438},\n",
       " {0: 0.936125636100769, 1: 0.06387436389923096},\n",
       " {0: 0.18410736322402954, 1: 0.8158926367759705},\n",
       " {0: 0.003150761127471924, 1: 0.9968492388725281},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.9957019686698914, 1: 0.004298031330108643},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.801645815372467, 1: 0.19835418462753296},\n",
       " {0: 0.9945027828216553, 1: 0.0054972171783447266},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.9727162718772888, 1: 0.02728372812271118},\n",
       " {0: 0.9947108030319214, 1: 0.005289196968078613},\n",
       " {0: 0.003150761127471924, 1: 0.9968492388725281},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.006348013877868652, 1: 0.9936519861221313},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.09489649534225464, 1: 0.9051035046577454},\n",
       " {0: 0.7436055541038513, 1: 0.2563944458961487},\n",
       " {0: 0.9638819694519043, 1: 0.0361180305480957},\n",
       " {0: 0.7801820039749146, 1: 0.21981799602508545},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.20657551288604736, 1: 0.7934244871139526},\n",
       " {0: 0.9787092208862305, 1: 0.02129077911376953},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.9963307976722717, 1: 0.0036692023277282715},\n",
       " {0: 0.9884804487228394, 1: 0.011519551277160645},\n",
       " {0: 0.9908865690231323, 1: 0.009113430976867676},\n",
       " {0: 0.00927501916885376, 1: 0.9907249808311462},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.006260871887207031, 1: 0.993739128112793},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.027588844299316406, 1: 0.9724111557006836},\n",
       " {0: 0.3840342164039612, 1: 0.6159657835960388},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.0179862380027771, 1: 0.9820137619972229},\n",
       " {0: 0.9918708801269531, 1: 0.008129119873046875},\n",
       " {0: 0.005192935466766357, 1: 0.9948070645332336},\n",
       " {0: 0.993239164352417, 1: 0.006760835647583008},\n",
       " {0: 0.9877086877822876, 1: 0.012291312217712402},\n",
       " {0: 0.06514698266983032, 1: 0.9348530173301697},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.9538043141365051, 1: 0.04619568586349487},\n",
       " {0: 0.9975855350494385, 1: 0.0024144649505615234},\n",
       " {0: 0.9885600209236145, 1: 0.011439979076385498},\n",
       " {0: 0.9986521601676941, 1: 0.0013478398323059082},\n",
       " {0: 0.32795798778533936, 1: 0.6720420122146606},\n",
       " {0: 0.008217334747314453, 1: 0.9917826652526855},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.9932004809379578, 1: 0.006799519062042236},\n",
       " {0: 0.5135136842727661, 1: 0.4864863157272339},\n",
       " {0: 0.9770506620407104, 1: 0.02294933795928955},\n",
       " {0: 0.0042612552642822266, 1: 0.9957387447357178},\n",
       " {0: 0.6769316792488098, 1: 0.3230683207511902},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.9608273506164551, 1: 0.03917264938354492},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.8571441173553467, 1: 0.14285588264465332},\n",
       " {0: 0.9978199005126953, 1: 0.0021800994873046875},\n",
       " {0: 0.07605522871017456, 1: 0.9239447712898254},\n",
       " {0: 0.9958208799362183, 1: 0.004179120063781738},\n",
       " {0: 0.9572039246559143, 1: 0.04279607534408569},\n",
       " {0: 0.9120506644248962, 1: 0.08794933557510376},\n",
       " {0: 0.621996283531189, 1: 0.37800371646881104},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9207722544670105, 1: 0.0792277455329895},\n",
       " {0: 0.9096214175224304, 1: 0.09037858247756958},\n",
       " {0: 0.09489649534225464, 1: 0.9051035046577454},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.9807291626930237, 1: 0.01927083730697632},\n",
       " {0: 0.9538043141365051, 1: 0.04619568586349487},\n",
       " {0: 0.9924821257591248, 1: 0.007517874240875244},\n",
       " {0: 0.007355093955993652, 1: 0.9926449060440063},\n",
       " {0: 0.7179663181304932, 1: 0.28203368186950684},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9966841340065002, 1: 0.003315865993499756},\n",
       " {0: 0.006714046001434326, 1: 0.9932859539985657},\n",
       " {0: 0.9860469698905945, 1: 0.013953030109405518},\n",
       " {0: 0.9810011982917786, 1: 0.018998801708221436},\n",
       " {0: 0.3379531502723694, 1: 0.6620468497276306},\n",
       " {0: 0.003204524517059326, 1: 0.9967954754829407},\n",
       " {0: 0.375521183013916, 1: 0.624478816986084},\n",
       " {0: 0.9818673133850098, 1: 0.018132686614990234},\n",
       " {0: 0.9987087249755859, 1: 0.0012912750244140625},\n",
       " {0: 0.9991362690925598, 1: 0.0008637309074401855},\n",
       " {0: 0.932655930519104, 1: 0.067344069480896},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9469522833824158, 1: 0.05304771661758423},\n",
       " {0: 0.06530982255935669, 1: 0.9346901774406433},\n",
       " {0: 0.9774162769317627, 1: 0.022583723068237305},\n",
       " {0: 0.7797511219978333, 1: 0.22024887800216675},\n",
       " {0: 0.007742404937744141, 1: 0.9922575950622559},\n",
       " {0: 0.9592908620834351, 1: 0.04070913791656494},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.9608273506164551, 1: 0.03917264938354492},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.992379903793335, 1: 0.007620096206665039},\n",
       " {0: 0.7344350218772888, 1: 0.2655649781227112},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.004022002220153809, 1: 0.9959779977798462},\n",
       " {0: 0.22149640321731567, 1: 0.7785035967826843},\n",
       " {0: 0.0031633377075195312, 1: 0.9968366622924805},\n",
       " {0: 0.7911086082458496, 1: 0.2088913917541504},\n",
       " {0: 0.9995018243789673, 1: 0.0004981756210327148},\n",
       " {0: 0.9899842739105225, 1: 0.010015726089477539},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " {0: 0.004022002220153809, 1: 0.9959779977798462},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.22149640321731567, 1: 0.7785035967826843},\n",
       " {0: 0.00960630178451538, 1: 0.9903936982154846},\n",
       " {0: 0.05347257852554321, 1: 0.9465274214744568},\n",
       " {0: 0.007355093955993652, 1: 0.9926449060440063},\n",
       " {0: 0.9994799494743347, 1: 0.0005200505256652832},\n",
       " {0: 0.9978261590003967, 1: 0.0021738409996032715},\n",
       " {0: 0.8670415878295898, 1: 0.13295841217041016},\n",
       " {0: 0.013731956481933594, 1: 0.9862680435180664},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.9866373538970947, 1: 0.013362646102905273},\n",
       " {0: 0.9861887097358704, 1: 0.013811290264129639},\n",
       " {0: 0.9981508851051331, 1: 0.0018491148948669434},\n",
       " {0: 0.9794615507125854, 1: 0.02053844928741455},\n",
       " {0: 0.08216279745101929, 1: 0.9178372025489807},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.22639036178588867, 1: 0.7736096382141113},\n",
       " {0: 0.999268114566803, 1: 0.0007318854331970215},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.9951775074005127, 1: 0.004822492599487305},\n",
       " {0: 0.9993096590042114, 1: 0.0006903409957885742},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.9058070182800293, 1: 0.0941929817199707},\n",
       " {0: 0.6193292737007141, 1: 0.3806707262992859},\n",
       " {0: 0.9908865690231323, 1: 0.009113430976867676},\n",
       " {0: 0.3160681128501892, 1: 0.6839318871498108},\n",
       " {0: 0.993861198425293, 1: 0.006138801574707031},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.3834582567214966, 1: 0.6165417432785034},\n",
       " {0: 0.959701418876648, 1: 0.04029858112335205},\n",
       " {0: 0.9782282114028931, 1: 0.021771788597106934},\n",
       " {0: 0.09489649534225464, 1: 0.9051035046577454},\n",
       " {0: 0.9790638089179993, 1: 0.020936191082000732},\n",
       " {0: 0.9906576871871948, 1: 0.009342312812805176},\n",
       " {0: 0.23038655519485474, 1: 0.7696134448051453},\n",
       " {0: 0.989133894443512, 1: 0.010866105556488037},\n",
       " {0: 0.47996026277542114, 1: 0.5200397372245789},\n",
       " {0: 0.9444093108177185, 1: 0.055590689182281494},\n",
       " {0: 0.9649277329444885, 1: 0.035072267055511475},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.07997256517410278, 1: 0.9200274348258972},\n",
       " {0: 0.07605522871017456, 1: 0.9239447712898254},\n",
       " {0: 0.9985483288764954, 1: 0.0014516711235046387},\n",
       " {0: 0.6769316792488098, 1: 0.3230683207511902},\n",
       " {0: 0.9959114789962769, 1: 0.0040885210037231445},\n",
       " {0: 0.47517240047454834, 1: 0.5248275995254517},\n",
       " {0: 0.6252903342247009, 1: 0.3747096657752991},\n",
       " {0: 0.585845410823822, 1: 0.414154589176178},\n",
       " {0: 0.4566394090652466, 1: 0.5433605909347534},\n",
       " {0: 0.3834582567214966, 1: 0.6165417432785034},\n",
       " {0: 0.9774162769317627, 1: 0.022583723068237305},\n",
       " {0: 0.47996026277542114, 1: 0.5200397372245789},\n",
       " {0: 0.9835010766983032, 1: 0.016498923301696777},\n",
       " {0: 0.9473990201950073, 1: 0.052600979804992676},\n",
       " {0: 0.01105797290802002, 1: 0.98894202709198},\n",
       " {0: 0.008638203144073486, 1: 0.9913617968559265},\n",
       " {0: 0.9481639862060547, 1: 0.05183601379394531},\n",
       " {0: 0.47477638721466064, 1: 0.5252236127853394},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.9986028075218201, 1: 0.0013971924781799316},\n",
       " {0: 0.0163266658782959, 1: 0.9836733341217041},\n",
       " {0: 0.2788711190223694, 1: 0.7211288809776306},\n",
       " {0: 0.0031633377075195312, 1: 0.9968366622924805},\n",
       " {0: 0.27686411142349243, 1: 0.7231358885765076},\n",
       " {0: 0.9965144991874695, 1: 0.0034855008125305176},\n",
       " {0: 0.6653146743774414, 1: 0.3346853256225586},\n",
       " {0: 0.9845741391181946, 1: 0.01542586088180542},\n",
       " {0: 0.7801820039749146, 1: 0.21981799602508545},\n",
       " {0: 0.9929314851760864, 1: 0.007068514823913574},\n",
       " {0: 0.6244694590568542, 1: 0.37553054094314575},\n",
       " {0: 0.0038518905639648438, 1: 0.9961481094360352},\n",
       " {0: 0.9034430384635925, 1: 0.09655696153640747},\n",
       " {0: 0.9835010766983032, 1: 0.016498923301696777},\n",
       " {0: 0.9921445250511169, 1: 0.007855474948883057},\n",
       " {0: 0.0627661943435669, 1: 0.9372338056564331},\n",
       " {0: 0.010600924491882324, 1: 0.9893990755081177},\n",
       " {0: 0.2420719861984253, 1: 0.7579280138015747},\n",
       " {0: 0.9088375568389893, 1: 0.09116244316101074},\n",
       " {0: 0.001548171043395996, 1: 0.998451828956604},\n",
       " {0: 0.5365029573440552, 1: 0.4634970426559448},\n",
       " {0: 0.006260871887207031, 1: 0.993739128112793},\n",
       " {0: 0.021264970302581787, 1: 0.9787350296974182},\n",
       " {0: 0.9951775074005127, 1: 0.004822492599487305},\n",
       " {0: 0.9989902377128601, 1: 0.0010097622871398926},\n",
       " {0: 0.007627606391906738, 1: 0.9923723936080933},\n",
       " {0: 0.44982725381851196, 1: 0.550172746181488},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.0037493109703063965, 1: 0.9962506890296936},\n",
       " {0: 0.9141364693641663, 1: 0.08586353063583374},\n",
       " {0: 0.9945160746574402, 1: 0.0054839253425598145},\n",
       " {0: 0.5815711617469788, 1: 0.41842883825302124},\n",
       " {0: 0.021503686904907227, 1: 0.9784963130950928},\n",
       " {0: 0.9791166186332703, 1: 0.020883381366729736},\n",
       " {0: 0.8442471027374268, 1: 0.15575289726257324},\n",
       " {0: 0.9973383545875549, 1: 0.0026616454124450684},\n",
       " {0: 0.8813745975494385, 1: 0.11862540245056152},\n",
       " {0: 0.7801820039749146, 1: 0.21981799602508545},\n",
       " {0: 0.9982985854148865, 1: 0.0017014145851135254},\n",
       " {0: 0.25612330436706543, 1: 0.7438766956329346},\n",
       " {0: 0.9843946695327759, 1: 0.015605330467224121},\n",
       " {0: 0.7143669128417969, 1: 0.2856330871582031},\n",
       " {0: 0.9908865690231323, 1: 0.009113430976867676},\n",
       " {0: 0.19407105445861816, 1: 0.8059289455413818},\n",
       " {0: 0.34091275930404663, 1: 0.6590872406959534},\n",
       " {0: 0.8421373963356018, 1: 0.1578626036643982},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.978116512298584, 1: 0.021883487701416016},\n",
       " {0: 0.9595311284065247, 1: 0.04046887159347534},\n",
       " {0: 0.8689004182815552, 1: 0.13109958171844482},\n",
       " {0: 0.01105797290802002, 1: 0.98894202709198},\n",
       " {0: 0.20657551288604736, 1: 0.7934244871139526},\n",
       " {0: 0.9958264231681824, 1: 0.004173576831817627},\n",
       " {0: 0.9974167346954346, 1: 0.0025832653045654297},\n",
       " {0: 0.22149640321731567, 1: 0.7785035967826843},\n",
       " {0: 0.9120678305625916, 1: 0.08793216943740845},\n",
       " {0: 0.9954427480697632, 1: 0.004557251930236816},\n",
       " {0: 0.007276475429534912, 1: 0.9927235245704651},\n",
       " {0: 0.9798459410667419, 1: 0.020154058933258057},\n",
       " {0: 0.9455702900886536, 1: 0.054429709911346436},\n",
       " {0: 0.9975364208221436, 1: 0.0024635791778564453},\n",
       " {0: 0.8025003671646118, 1: 0.19749963283538818},\n",
       " {0: 0.8447470664978027, 1: 0.15525293350219727},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9532202482223511, 1: 0.046779751777648926},\n",
       " {0: 0.008733093738555908, 1: 0.9912669062614441},\n",
       " {0: 0.5889708399772644, 1: 0.4110291600227356},\n",
       " {0: 0.8029220104217529, 1: 0.19707798957824707},\n",
       " {0: 0.4779035449028015, 1: 0.5220964550971985},\n",
       " {0: 0.9771775603294373, 1: 0.022822439670562744},\n",
       " {0: 0.743157148361206, 1: 0.25684285163879395},\n",
       " {0: 0.0037493109703063965, 1: 0.9962506890296936},\n",
       " {0: 0.9916081428527832, 1: 0.008391857147216797},\n",
       " {0: 0.984163224697113, 1: 0.015836775302886963},\n",
       " {0: 0.989301860332489, 1: 0.010698139667510986},\n",
       " {0: 0.8584163188934326, 1: 0.14158368110656738},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.9835010766983032, 1: 0.016498923301696777},\n",
       " {0: 0.07591694593429565, 1: 0.9240830540657043},\n",
       " {0: 0.10513937473297119, 1: 0.8948606252670288},\n",
       " {0: 0.8655325174331665, 1: 0.1344674825668335},\n",
       " {0: 0.9585064649581909, 1: 0.04149353504180908},\n",
       " {0: 0.0627661943435669, 1: 0.9372338056564331},\n",
       " {0: 0.007355093955993652, 1: 0.9926449060440063},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.6759709715843201, 1: 0.32402902841567993},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.8709043264389038, 1: 0.1290956735610962},\n",
       " {0: 0.007355093955993652, 1: 0.9926449060440063},\n",
       " {0: 0.057643353939056396, 1: 0.9423566460609436},\n",
       " {0: 0.5365029573440552, 1: 0.4634970426559448},\n",
       " {0: 0.3567408323287964, 1: 0.6432591676712036},\n",
       " {0: 0.008592963218688965, 1: 0.991407036781311},\n",
       " {0: 0.2151889204978943, 1: 0.7848110795021057},\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895011b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "HellowKedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
