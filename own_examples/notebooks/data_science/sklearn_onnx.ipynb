{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aee751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List, Any\n",
    "import datetime as dt\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "from category_encoders import CountEncoder, WOEEncoder\n",
    "from kedro.framework.session import KedroSession\n",
    "from kedro.framework.startup import bootstrap_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010b9176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:16,356 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n"
     ]
    }
   ],
   "source": [
    "# use config with base\n",
    "metadata = bootstrap_project(Path.cwd().parent.parent)\n",
    "with KedroSession.create(metadata.package_name,\n",
    "        project_path=metadata.project_path,\n",
    "        # save_on_close=True,\n",
    "        env=None,\n",
    "        # extra_params=extra_params\n",
    "    ) as session: \n",
    "    context = session.load_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f6634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_size': 0.2,\n",
       " 'random_state': 3,\n",
       " 'features': ['engines',\n",
       "  'passenger_capacity',\n",
       "  'crew',\n",
       "  'company_rating',\n",
       "  'review_scores_rating',\n",
       "  'd_check_complete',\n",
       "  'moon_clearance_complete',\n",
       "  'iata_approved'],\n",
       " 'categorical_features': ['d_check_complete',\n",
       "  'moon_clearance_complete',\n",
       "  'iata_approved'],\n",
       " 'model_params': {'hyper_parameters': {'max_depth': 7,\n",
       "   'n_estimators': 30,\n",
       "   'random_state': 555}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da946bc1",
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# regressor = xgb.sklearn.XGBRegressor(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "regressor = xgb.sklearn.XGBClassifier(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"ce\", WOEEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"float_input\", \"passthrough\", [context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]),\n",
    "        (\"categorical_input\", categorical_transformer, [context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]),\n",
    "    ],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    # Bad!\n",
    "    # (\"selector\", ColumnTransformer(\n",
    "    #     [(\"id\", \n",
    "    #       FunctionTransformer(validate=False),\n",
    "    #       list(range(len(context.params[\"features\"]))))\n",
    "    #     ])\n",
    "    # ),\n",
    "    # (\"selector\", CoulmnTransformer(FunctionTransformer(lambda X: X[:, list(range(len(context.params[\"features\"])))], validate=False))),\n",
    "    (\"precprocessor\", preprocessor),\n",
    "    (\"regressor\", regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4541b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113238f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d0eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/kedro/framework/context/context.py:488: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/kedro-sample/own_examples/conf/base', '/kedro-sample/own_examples/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:17,325 - kedro.io.data_catalog - INFO - Loading data from `X_train` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "tmp = context.catalog.load(\"X_train\")\n",
    "tmp[context.params[\"categorical_features\"]] = tmp[context.params[\"categorical_features\"]].astype(str)\n",
    "tmp[\"aaaaa\"] = tmp.engines.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46392b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:18,090 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:18,122 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25cde79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:18,464 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:18,486 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:08:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    # tmp[context.params[\"features\"]].values\n",
    "    tmp[context.params[\"features\"]+[\"aaaaa\"]].values\n",
    "    # ,context.catalog.load(\"y_train\")\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e382d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7748882 , 0.22511178],\n",
       "       [0.00519294, 0.99480706],\n",
       "       [0.9798459 , 0.0201541 ],\n",
       "       ...,\n",
       "       [0.9973383 , 0.00266168],\n",
       "       [0.9860327 , 0.01396728],\n",
       "       [0.80912876, 0.19087121]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict_proba(tmp[context.params[\"features\"]+[\"aaaaa\"]].values)\n",
    "# ppl.predict(tmp[context.params[\"features\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48448c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:23,125 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:08:23,146 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "[03:08:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    tmp[context.params[\"features\"]].values\n",
    "    # ,context.catalog.load(\"y_train\")\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98597110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict(tmp[context.params[\"features\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb123c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engines</th>\n",
       "      <th>passenger_capacity</th>\n",
       "      <th>crew</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>d_check_complete</th>\n",
       "      <th>moon_clearance_complete</th>\n",
       "      <th>iata_approved</th>\n",
       "      <th>aaaaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115794</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238624</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389153</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628283</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452204</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        engines  passenger_capacity  crew  company_rating  \\\n",
       "115794      2.0                   4   3.0             1.0   \n",
       "238624      4.0                   8   5.0             1.0   \n",
       "389153      1.0                   2   1.0             1.0   \n",
       "628283      2.0                   6   2.0             1.0   \n",
       "452204      1.0                   2   1.0             1.0   \n",
       "\n",
       "        review_scores_rating d_check_complete moon_clearance_complete  \\\n",
       "115794                  96.0            False                   False   \n",
       "238624                 100.0             True                   False   \n",
       "389153                  65.0             True                   False   \n",
       "628283                 100.0             True                   False   \n",
       "452204                  60.0             True                   False   \n",
       "\n",
       "       iata_approved  aaaaa  \n",
       "115794          True    2.0  \n",
       "238624         False    4.0  \n",
       "389153         False    1.0  \n",
       "628283         False    2.0  \n",
       "452204         False    1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[context.params[\"features\"]+[\"aaaaa\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf24b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607687, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f670921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  int(TensorProto.STRING): np.dtype(np.object)\n"
     ]
    },
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'category_encoders.woe.WOEEncoder'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18372/565559214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])+1])),\n\u001b[1;32m      5\u001b[0m                 (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_onnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m     onnx_model = convert_topology(\n\u001b[1;32m    185\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         remove_identity=not intermediate, verbose=verbose)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1226\u001b[0m                         \u001b[0m_check_variable_out_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Shape2] call infer_types for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_graph_status_for_traversing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36minfer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m             raise MissingShapeCalculator(\n\u001b[1;32m    572\u001b[0m                 \"Unable to find a shape calculator for type '{}'.\".format(\n\u001b[0;32m--> 573\u001b[0;31m                     type(self.raw_operator)))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mshape_calc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'category_encoders.woe.WOEEncoder'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])+1])),\n",
    "                (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36739b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:40,922 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/kedro/framework/context/context.py:488: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/kedro-sample/own_examples/conf/base', '/kedro-sample/own_examples/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151922, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.catalog.load(\"X_test\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ccf5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:41,689 - kedro.io.data_catalog - INFO - Loading data from `regressor` (PickleDataSet)...\n",
      "2021-12-27 03:08:41,711 - kedro.io.data_catalog - INFO - Saving data to `onx` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "initial_type = [('float_input', FloatTensorType([None, 8]))]\n",
    "onx = convert_sklearn(context.catalog.load(\"regressor\"), initial_types=initial_type)\n",
    "context.catalog.save(\"onx\", onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0474a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/06_models/shuttles.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a07d6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:08:43,055 - kedro.io.data_catalog - INFO - Loading data from `onx` (PickleDataSet)...\n",
      "2021-12-27 03:08:43,090 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy\n",
    "sess = rt.InferenceSession(context.catalog.load(\"onx\"))\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: context.catalog.load(\"X_test\").astype(numpy.float32).values})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e5df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5788.9775],\n",
       "       [3973.5654],\n",
       "       [3594.4954],\n",
       "       ...,\n",
       "       [3748.6594],\n",
       "       [5454.851 ],\n",
       "       [4444.2515]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6a0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf2c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder as SklOrdinalEncoder\n",
    "from category_encoders import WOEEncoder, OrdinalEncoder\n",
    "from skl2onnx import update_registered_converter, get_model_alias\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.utils import check_input_and_output_numbers\n",
    "from skl2onnx.algebra.onnx_ops import OnnxCast\n",
    "from skl2onnx.algebra.onnx_operator import OnnxSubEstimator\n",
    "from skl2onnx.sklapi import WOETransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6966aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordenc_to_sklearn(op_mapping):\n",
    "    \"Converts OrdinalEncoder mapping to scikit-learn OrdinalEncoder.\"\n",
    "    cats = []\n",
    "    for column_map in op_mapping:\n",
    "        col = column_map['col']\n",
    "        print(col)\n",
    "        while len(cats) <= col:\n",
    "            cats.append(None)\n",
    "        mapping = column_map['mapping']\n",
    "        print(mapping)\n",
    "        print(mapping.index[0])\n",
    "        res = []\n",
    "        for i in range(mapping.shape[0]):\n",
    "            if mapping.index[i]!=mapping.index[i]:\n",
    "                continue\n",
    "            ind = mapping.iloc[i]\n",
    "            print(\"ind\",ind)\n",
    "            while len(res) <= ind:\n",
    "                res.append(0)\n",
    "            res[ind] = mapping.index[i]\n",
    "        cats[col] = np.array(res, dtype=\"O\")\n",
    "\n",
    "    skl_ord = SklOrdinalEncoder(categories=cats, dtype=np.int64)\n",
    "    skl_ord.categories_ = cats\n",
    "    return skl_ord\n",
    "\n",
    "\n",
    "def ordinal_encoder_shape_calculator(operator):\n",
    "    check_input_and_output_numbers(\n",
    "        operator, input_count_range=1, output_count_range=1)\n",
    "    input_type = operator.inputs[0].type.__class__\n",
    "    input_dim = operator.inputs[0].get_first_dimension()\n",
    "    shape = operator.inputs[0].type.shape\n",
    "    second_dim = None if len(shape) != 2 else shape[1]\n",
    "    output_type = input_type([input_dim, second_dim])\n",
    "    operator.outputs[0].type = output_type\n",
    "\n",
    "\n",
    "def ordinal_encoder_converter(scope, operator, container):\n",
    "    op = operator.raw_operator\n",
    "    opv = container.target_opset\n",
    "    X = operator.inputs[0]\n",
    "\n",
    "    skl_ord = ordenc_to_sklearn(op.mapping)\n",
    "    cat = OnnxSubEstimator(skl_ord, X, op_version=opv,\n",
    "                           output_names=operator.outputs[:1])\n",
    "    cat.add_to(scope, container)\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    OrdinalEncoder, \"CategoricalEncoderOrdinalEncoder\",\n",
    "    ordinal_encoder_shape_calculator,\n",
    "    ordinal_encoder_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96df57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def woeenc_to_sklearn(op_mapping):\n",
    "    \"Converts WOEEncoder mapping to scikit-learn OrdinalEncoder.\"\n",
    "    cats = []\n",
    "    ws = []\n",
    "    for column_map in op_mapping.items():\n",
    "        col = column_map[0]\n",
    "        while len(cats) <= col:\n",
    "            cats.append('passthrough')\n",
    "            ws.append(None)\n",
    "        mapping = column_map[1]\n",
    "        intervals = []\n",
    "        weights = []\n",
    "        for i in range(mapping.shape[0]):\n",
    "            ind = mapping.index[i]\n",
    "            if ind < 0:\n",
    "                continue\n",
    "            intervals.append((float(ind - 1), float(ind), False, True))\n",
    "            weights.append(mapping.iloc[i])\n",
    "        cats[col] = intervals\n",
    "        ws[col] = weights\n",
    "\n",
    "    skl = WOETransformer(intervals=cats, weights=ws, onehot=False)\n",
    "    skl.fit(None)\n",
    "    return skl\n",
    "\n",
    "\n",
    "def woe_encoder_parser(\n",
    "        scope, model, inputs, custom_parsers=None):\n",
    "    if len(inputs) != 1:\n",
    "        raise RuntimeError(\n",
    "            \"Unexpected number of inputs: %d != 1.\" % len(inputs))\n",
    "    if inputs[0].type is None:\n",
    "        raise RuntimeError(\n",
    "            \"Unexpected type: %r.\" % (inputs[0], ))\n",
    "    alias = get_model_alias(type(model))\n",
    "    this_operator = scope.declare_local_operator(alias, model)\n",
    "    this_operator.inputs.append(inputs[0])\n",
    "    this_operator.outputs.append(\n",
    "        scope.declare_local_variable('catwoe', FloatTensorType()))\n",
    "    return this_operator.outputs\n",
    "\n",
    "\n",
    "def woe_encoder_shape_calculator(operator):\n",
    "    check_input_and_output_numbers(\n",
    "        operator, input_count_range=1, output_count_range=1)\n",
    "    input_dim = operator.inputs[0].get_first_dimension()\n",
    "    shape = operator.inputs[0].type.shape\n",
    "    second_dim = None if len(shape) != 2 else shape[1]\n",
    "    output_type = FloatTensorType([input_dim, second_dim])\n",
    "    operator.outputs[0].type = output_type\n",
    "\n",
    "\n",
    "def woe_encoder_converter(scope, operator, container):\n",
    "    op = operator.raw_operator\n",
    "    opv = container.target_opset\n",
    "    X = operator.inputs[0]\n",
    "\n",
    "    sub = OnnxSubEstimator(op.ordinal_encoder, X,\n",
    "                           op_version=opv)\n",
    "    cast = OnnxCast(sub, op_version=opv, to=np.float32)\n",
    "    skl_ord = woeenc_to_sklearn(op.mapping)\n",
    "    cat = OnnxSubEstimator(skl_ord, cast, op_version=opv,\n",
    "                           output_names=operator.outputs[:1],\n",
    "                           input_types=[FloatTensorType()])\n",
    "    cat.add_to(scope, container)\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    WOEEncoder, \"CategoricalEncoderWOEEncoder\",\n",
    "    woe_encoder_shape_calculator,\n",
    "    woe_encoder_converter,\n",
    "    parser=woe_encoder_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0085adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "\n",
    "update_registered_converter(\n",
    "    XGBClassifier, 'XGBoostXGBClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df426802",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(**context.params[\"model_params\"][\"hyper_parameters\"])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"we\", WOEEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", \"passthrough\", [context.params[\"features\"].index(cf) for cf in context.params[\"features\"] if cf not in context.params[\"categorical_features\"]]),\n",
    "        (\"categorical\", categorical_transformer, [context.params[\"features\"].index(cf) for cf in context.params[\"categorical_features\"]]),\n",
    "    ],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"precprocessor\", preprocessor),\n",
    "    (\"regressor\", classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "007ec169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:31:34,898 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2021-12-27 03:31:34,920 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/kedro/framework/context/context.py:488: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/kedro-sample/own_examples/conf/base', '/kedro-sample/own_examples/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:31:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ppl = model.fit(\n",
    "    tmp[context.params[\"features\"]].values\n",
    "    ,np.where(context.catalog.load(\"y_train\")<context.catalog.load(\"y_train\").mean(), 0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00b5d831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "085ed52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False    1\n",
      "True     2\n",
      "NaN     -2\n",
      "dtype: int64\n",
      "False\n",
      "ind 1\n",
      "ind 2\n",
      "1\n",
      "False    1\n",
      "NaN     -2\n",
      "dtype: int64\n",
      "False\n",
      "ind 1\n",
      "2\n",
      "True     1\n",
      "False    2\n",
      "NaN     -2\n",
      "dtype: int64\n",
      "True\n",
      "ind 1\n",
      "ind 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/onnx/numpy_helper.py:93: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if arr.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "initial_type = [(\"float_input\", FloatTensorType([None, len(context.params[\"features\"]) - len(context.params[\"categorical_features\"])])),\n",
    "                (\"categorical_input\", StringTensorType([None, len(context.params[\"categorical_features\"])]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad0bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27187eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b162db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c640764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf5e86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed4b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35434f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a098e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56f19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a4f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84588bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca9af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1411b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15bb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a14ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b9d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bfb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ee57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "HellowKedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
